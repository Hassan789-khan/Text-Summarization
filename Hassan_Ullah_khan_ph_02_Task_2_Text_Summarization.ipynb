{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZwevedvlTyW"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets spacy nltk rouge-score\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "from heapq import nlargest\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "5h_wJM2FpThj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'<[^>]+>', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "h0u77uzEqFF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extractive_summary(text, num_sentences=3):\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    doc = nlp(text)\n",
        "    sentence_scores = {}\n",
        "    for sent in doc.sents:\n",
        "        for word in sent:\n",
        "            if word.is_stop == False and word.is_alpha:\n",
        "                sentence_scores[sent] = sentence_scores.get(sent, 0) + 1\n",
        "    summary = nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
        "    return ' '.join([str(s) for s in summary])\n"
      ],
      "metadata": {
        "id": "dOiuBv_jqG2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "def abstractive_summary(text):\n",
        "    summary = summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
        "    return summary[0]['summary_text']\n"
      ],
      "metadata": {
        "id": "wI0idy1MqKq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"cnn_dailymail\", '3.0.0')\n",
        "sample = dataset['test'][0]\n",
        "print(\"Original Article:\\n\", sample['article'])\n",
        "print(\"Reference Summary:\\n\", sample['highlights'])\n"
      ],
      "metadata": {
        "id": "5UqhnxvpqUb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = preprocess_text(sample['article'])\n",
        "\n",
        "print(\"\\nExtractive Summary:\\n\", extractive_summary(text))\n",
        "print(\"\\nAbstractive Summary:\\n\", abstractive_summary(text))\n"
      ],
      "metadata": {
        "id": "rAF7jLPLqgps"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}